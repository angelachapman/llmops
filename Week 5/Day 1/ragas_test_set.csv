,question,contexts,ground_truth,evolution_type,metadata,episode_done
0,What types of financial institutions are subject to requirements under Directive 2009/138/EC?,"['undertakings and insurance holding companies under Directive 2009/138/EC and the insurance intermediaries under Directive (EU) 2016/97 and other types of financial institutions subject to requirements regarding internal governance, arrangements or processes established pursuant to the relevant Union financial services law to ensure consistency and equal treatment in the financial sector.']",Insurance holding companies and undertakings are subject to requirements under Directive 2009/138/EC.,simple,"[{'source': 'eu_ai_act.html', 'id': '88508114-945d-4932-84e1-a6a22035763a'}]",True
1,How can market surveillance authorities request assistance from the AI Office in cases where they are unable to conclude an investigation on a high-risk AI system?,"['one purpose that is classified as high-risk, market surveillance authorities should cooperate with the AI Office to carry out evaluations of compliance and inform the Board and other market surveillance authorities accordingly. Furthermore, market surveillance authorities should be able to request assistance from the AI Office where the market surveillance authority is unable to conclude an investigation on a\xa0high-risk AI system because of its inability to access certain information related to the general-purpose AI model on which the high-risk AI system is built. In such cases, the procedure regarding mutual assistance in cross-border cases in Chapter\xa0VI of Regulation (EU) 2019/1020 should apply mutatis mutandis .']","Market surveillance authorities can request assistance from the AI Office in cases where they are unable to conclude an investigation on a high-risk AI system by cooperating with the AI Office to carry out evaluations of compliance and informing the Board and other market surveillance authorities accordingly. If the market surveillance authority is unable to access certain information related to the general-purpose AI model on which the high-risk AI system is built, they can request assistance from the AI Office. In such cases, the procedure regarding mutual assistance in cross-border cases in Chapter VI of Regulation (EU) 2019/1020 should apply mutatis mutandis.",simple,"[{'source': 'eu_ai_act.html', 'id': 'af7789d9-fbfe-4327-9c03-82080f99922f'}]",True
2,How can providers of AI systems that are not high-risk be encouraged to create codes of conduct to foster the voluntary application of mandatory requirements?,"['(165) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a\xa0larger uptake of ethical and trustworthy AI in the Union. Providers of AI systems that are not high-risk should be encouraged to create codes of conduct, including related governance mechanisms, intended to foster the voluntary application of some or all of the mandatory requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved and taking into account the available technical solutions and industry best practices such as model and data cards. Providers and, as appropriate, deployers of all AI systems, high-risk or not, and AI models']","Providers of AI systems that are not high-risk can be encouraged to create codes of conduct, including related governance mechanisms, intended to foster the voluntary application of some or all of the mandatory requirements applicable to high-risk AI systems. This can be adapted in light of the intended purpose of the systems and the lower risk involved, taking into account available technical solutions and industry best practices such as model and data cards.",simple,"[{'source': 'eu_ai_act.html', 'id': '70c348c6-fab5-441c-a6f8-73e944c84482'}]",True
3,What rules and requirements are applicable to regulated financial institutions under Union financial services law?,"['(158) Union financial services law includes internal governance and risk-management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legal acts, the competent authorities for the supervision and enforcement of those legal acts, in particular competent authorities as defined in Regulation (EU) No\xa0575/2013 of the European Parliament and of the Council ( 46 ) and Directives 2008/48/EC ( 47 ) , 2009/138/EC ( 48 ) , 2013/36/EU ( 49 ) , 2014/17/EU ( 50 ) and (EU)']","Internal governance and risk-management rules and requirements are applicable to regulated financial institutions under Union financial services law, including when they make use of AI systems.",simple,"[{'source': 'eu_ai_act.html', 'id': 'f0f61388-a1d0-490e-8744-e6aa04cfb719'}]",True
4,How does the Regulation aim to enhance consistency between providers and credit institutions regulated under Directive 2013/36/EU?,"['To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU, it is also appropriate to integrate some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on deployers of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU. The same regime should apply to insurance and re-insurance undertakings and']","The Regulation aims to enhance consistency between providers and credit institutions regulated under Directive 2013/36/EU by integrating some of the providers' procedural obligations related to risk management, post-marketing monitoring, and documentation into the existing obligations and procedures under Directive 2013/36/EU. Limited derogations are also envisaged in relation to the quality management system of providers and the monitoring obligation on deployers of high-risk AI systems, to avoid overlaps with the obligations of credit institutions regulated by Directive 2013/36/EU.",simple,"[{'source': 'eu_ai_act.html', 'id': '4a8396dc-0e76-4246-a3b5-e4c389f06ff4'}]",True
5,How do national authorities report information to the European Central Bank in relation to market surveillance activities?,"['as appropriate, into their existing supervisory mechanisms and procedures under the relevant Union financial services law. It is appropriate to envisage that, when acting as market surveillance authorities under this Regulation, the national authorities responsible for the supervision of credit institutions regulated under Directive 2013/36/EU, which are participating in the Single Supervisory Mechanism established by Council Regulation (EU)\xa0No\xa01024/2013 ( 52 ) , should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank’s prudential supervisory tasks as specified in that Regulation. To further']","National authorities report information to the European Central Bank in relation to market surveillance activities by reporting, without delay, any information identified in the course of their activities that may be of potential interest for the European Central Bank's prudential supervisory tasks as specified in the relevant Regulation.",simple,"[{'source': 'eu_ai_act.html', 'id': '92d20938-ccc6-4efe-b72a-ba8f2ac153cc'}]",True
6,How can providers of high-risk AI systems take corrective action in a timely manner?,"['(155) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a\xa0timely manner, all providers should have a\xa0post-market monitoring system in place. Where relevant, post-market monitoring should include an analysis of the interaction with other AI systems including other devices and software. Post-market monitoring should not cover sensitive operational data of deployers which are law enforcement authorities. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put']","Providers of high-risk AI systems can take corrective action in a timely manner by having a post-market monitoring system in place. This system allows them to gather feedback on the use of their systems, identify areas for improvement, and address any issues that may arise promptly. Additionally, the post-market monitoring should include an analysis of the interaction with other AI systems and devices to ensure comprehensive oversight. However, sensitive operational data of law enforcement authorities should not be included in this monitoring process.",simple,"[{'source': 'eu_ai_act.html', 'id': '2c5ff16a-e3f9-4a5c-8b98-79ce96899d5f'}]",True
7,What role does Regulation (EU) 2019/1020 play in the supervision of AI systems based on general-purpose AI models?,"['(161) It is necessary to clarify the responsibilities and competences at Union and national level as regards AI systems that are built on general-purpose AI models. To avoid overlapping competences, where an AI system is based on a\xa0general-purpose AI model and the model and system are provided by the same provider, the supervision should take place at Union level through the AI Office, which should have the powers of a\xa0market surveillance authority within the meaning of Regulation (EU) 2019/1020 for this purpose. In all other cases, national market surveillance authorities remain responsible for the supervision of AI systems. However, for general-purpose AI systems that can be used directly by deployers for at least one purpose that is']","Regulation (EU) 2019/1020 plays a role in the supervision of AI systems based on general-purpose AI models by granting the AI Office at Union level the powers of a market surveillance authority in cases where the AI system is based on a general-purpose AI model provided by the same provider. In all other cases, national market surveillance authorities are responsible for the supervision of AI systems.",simple,"[{'source': 'eu_ai_act.html', 'id': 'ebad319b-a393-4e62-82b0-a779c12eeb13'}]",True
8,How can providers of AI systems that are not high-risk be encouraged to create codes of conduct to foster the voluntary application of mandatory requirements?,"['(165) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a\xa0larger uptake of ethical and trustworthy AI in the Union. Providers of AI systems that are not high-risk should be encouraged to create codes of conduct, including related governance mechanisms, intended to foster the voluntary application of some or all of the mandatory requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved and taking into account the available technical solutions and industry best practices such as model and data cards. Providers and, as appropriate, deployers of all AI systems, high-risk or not, and AI models']","Providers of AI systems that are not high-risk can be encouraged to create codes of conduct, including related governance mechanisms, intended to foster the voluntary application of some or all of the mandatory requirements applicable to high-risk AI systems. This can be adapted in light of the intended purpose of the systems and the lower risk involved, taking into account available technical solutions and industry best practices such as model and data cards.",simple,"[{'source': 'eu_ai_act.html', 'id': '70c348c6-fab5-441c-a6f8-73e944c84482'}]",True
9,How can market surveillance authorities and the Commission collaborate to promote compliance and identify non-compliance with respect to specific categories of high-risk AI systems?,"['(160) The market surveillance authorities and the Commission should be able to propose joint activities, including joint investigations, to be conducted by market surveillance authorities or market surveillance authorities jointly with the Commission, that have the aim of promoting compliance, identifying non-compliance, raising awareness and providing guidance in relation to this Regulation with respect to specific categories of high-risk AI systems that are found to present a\xa0serious risk across two or more Member States. Joint activities to promote compliance should be carried out in accordance with Article\xa09 of Regulation (EU) 2019/1020. The AI Office should provide coordination support for joint investigations.']","The market surveillance authorities and the Commission can propose joint activities, including joint investigations, to promote compliance, identify non-compliance, raise awareness, and provide guidance in relation to specific categories of high-risk AI systems that are found to present a serious risk across two or more Member States. These joint activities should be carried out in accordance with Article 9 of Regulation (EU) 2019/1020, with coordination support provided by the AI Office for joint investigations.",simple,"[{'source': 'eu_ai_act.html', 'id': 'fb5211e1-4279-446e-afba-eef577575d35'}]",True
10,How does the Regulation on high-risk AI systems ensure legal certainty and market continuity through an adaptation period for operators?,"['(177) In order to ensure legal certainty, ensure an appropriate adaptation period for operators and avoid disruption to the market, including by ensuring continuity of the use of AI systems, it is appropriate that this Regulation applies to the high-risk AI systems that have been placed on the market or put into service before the general date of application thereof, only if, from that date, those systems are subject to significant changes in their design or intended purpose. It is appropriate to clarify that, in this respect, the concept of significant change should be understood as equivalent in substance to the notion of substantial modification, which is used with regard only to high-risk AI systems pursuant to this Regulation. On an']","The Regulation on high-risk AI systems ensures legal certainty and market continuity through an adaptation period for operators by applying to high-risk AI systems that have been placed on the market or put into service before the general date of application only if those systems undergo significant changes in design or intended purpose. The concept of significant change is equivalent to substantial modification, ensuring that operators have time to adapt and avoid market disruption.",reasoning,"[{'source': 'eu_ai_act.html', 'id': '64328b97-dc5f-41e6-baa2-d3dca8596dc3'}]",True
11,How do national authorities transmit info to ECB under Directive 2013/36/EU?,"['as appropriate, into their existing supervisory mechanisms and procedures under the relevant Union financial services law. It is appropriate to envisage that, when acting as market surveillance authorities under this Regulation, the national authorities responsible for the supervision of credit institutions regulated under Directive 2013/36/EU, which are participating in the Single Supervisory Mechanism established by Council Regulation (EU)\xa0No\xa01024/2013 ( 52 ) , should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank’s prudential supervisory tasks as specified in that Regulation. To further']","National authorities transmit information to the European Central Bank (ECB) under Directive 2013/36/EU by reporting, without delay, any relevant information identified during their market surveillance activities that may be of interest for the ECB's prudential supervisory tasks as specified in the Regulation.",reasoning,"[{'source': 'eu_ai_act.html', 'id': '92d20938-ccc6-4efe-b72a-ba8f2ac153cc'}]",True
12,"Which authorities should oversee AI rules in finance, as per regulations?","['( 50 ) and (EU) 2016/97 ( 51 ) of the European Parliament and of the Council, should be designated, within their respective competences, as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions unless Member States decide to designate another authority to fulfil these market surveillance tasks. Those competent authorities should have all powers under this Regulation and Regulation (EU) 2019/1020 to enforce the requirements and obligations of this Regulation, including powers to carry our ex post market surveillance activities that can be integrated, as appropriate,']","The European Parliament and the Council should be designated as competent authorities for overseeing AI rules in finance, as per regulations.",reasoning,"[{'source': 'eu_ai_act.html', 'id': '8a99f1a2-9d8f-4b00-b4b3-543e96115a08'}]",True
13,Who oversees AI model regulations and how do they enforce compliance?,"['(162) To make best use of the centralised Union expertise and synergies at Union level, the powers of supervision and enforcement of the obligations on providers of general-purpose AI models should be a\xa0competence of the Commission. The AI Office should be able to carry out all necessary actions to monitor the effective implementation of this Regulation as regards general-purpose AI models. It should be able to investigate possible infringements of the rules on providers of general-purpose AI models both on its own initiative, following the results of its monitoring activities, or upon request from market surveillance authorities in line with the conditions set out in this Regulation. To support effective monitoring of the AI Office, it']","The Commission oversees AI model regulations and enforces compliance through the AI Office, which is empowered to supervise and enforce the obligations on providers of general-purpose AI models. The AI Office can monitor the effective implementation of regulations, investigate possible infringements, and take necessary actions to ensure compliance.",reasoning,"[{'source': 'eu_ai_act.html', 'id': 'e9c83fe5-3053-4357-9c1f-9f54cfa352e9'}]",True
14,"How do Member States' experts contribute to delegated acts in the EU Parliament and Council, and how can the scientific panel request documentation?","['the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.', 'for the performance of those tasks, there should be a\xa0mechanism whereby the scientific panel can request the Commission to require documentation or information from a\xa0provider.']",Member States' experts contribute to delegated acts in the EU Parliament and Council by receiving all documents at the same time as Member States' experts and having access to meetings of Commission expert groups dealing with the preparation of delegated acts. The scientific panel can request documentation or information from a provider by requesting the Commission to require such documentation or information.,multi_context,"[{'source': 'eu_ai_act.html', 'id': '91d99eca-edc9-4468-bf26-3ef3cfcac989'}, {'source': 'eu_ai_act.html', 'id': '9cefc918-c1b1-4495-a133-42c1056b848c'}]",True
15,"What defines incidents requiring reporting in AI system usage, including harm, infrastructure, legal obligations, and environmental impact?","['the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a\xa0system in place to report to the relevant authorities any serious incidents resulting from the use of their AI systems, meaning incident or malfunctioning leading to death or serious damage to health, serious and irreversible disruption of the management and operation of critical infrastructure, infringements of obligations under Union law intended to protect fundamental rights or serious damage to property or the environment.']","Providers should have a system in place to report serious incidents resulting from the use of their AI systems, including incidents or malfunctions leading to death or serious health damage, serious and irreversible disruption of critical infrastructure, infringements of obligations under Union law protecting fundamental rights, or serious damage to property or the environment.",multi_context,"[{'source': 'eu_ai_act.html', 'id': 'dd493490-9d6a-44b3-b6d8-45d1204a668a'}]",True
16,What roles do national market surveillance authorities and the AI Office play in overseeing AI systems based on general-purpose AI models?,"['(161) It is necessary to clarify the responsibilities and competences at Union and national level as regards AI systems that are built on general-purpose AI models. To avoid overlapping competences, where an AI system is based on a\xa0general-purpose AI model and the model and system are provided by the same provider, the supervision should take place at Union level through the AI Office, which should have the powers of a\xa0market surveillance authority within the meaning of Regulation (EU) 2019/1020 for this purpose. In all other cases, national market surveillance authorities remain responsible for the supervision of AI systems. However, for general-purpose AI systems that can be used directly by deployers for at least one purpose that is', '(162) To make best use of the centralised Union expertise and synergies at Union level, the powers of supervision and enforcement of the obligations on providers of general-purpose AI models should be a\xa0competence of the Commission. The AI Office should be able to carry out all necessary actions to monitor the effective implementation of this Regulation as regards general-purpose AI models. It should be able to investigate possible infringements of the rules on providers of general-purpose AI models both on its own initiative, following the results of its monitoring activities, or upon request from market surveillance authorities in line with the conditions set out in this Regulation. To support effective monitoring of the AI Office, it']","National market surveillance authorities are responsible for the supervision of AI systems unless the AI system is based on a general-purpose AI model provided by the same provider, in which case supervision takes place at Union level through the AI Office. The AI Office has the powers of a market surveillance authority within the meaning of Regulation (EU) 2019/1020 for this purpose.",multi_context,"[{'source': 'eu_ai_act.html', 'id': 'ebad319b-a393-4e62-82b0-a779c12eeb13'}, {'source': 'eu_ai_act.html', 'id': 'e9c83fe5-3053-4357-9c1f-9f54cfa352e9'}]",True
17,Who should shape AI codes for effectiveness and inclusivity?,"['To ensure that the voluntary codes of conduct are effective, they should be based on clear objectives and key performance indicators to measure the achievement of those objectives. They should also be developed in an inclusive way, as appropriate, with the involvement of relevant stakeholders such as business and civil society organisations, academia, research organisations, trade unions and consumer protection organisation. The Commission may develop initiatives, including of a\xa0sectoral nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.']","AI codes for effectiveness and inclusivity should be shaped by involving relevant stakeholders such as business and civil society organisations, academia, research organisations, trade unions, and consumer protection organisations. The Commission may also develop initiatives, including sectoral ones, to facilitate the lowering of technical barriers hindering cross-border data exchange for AI development.",multi_context,"[{'source': 'eu_ai_act.html', 'id': '0c6b8cfe-29c1-4eaf-9b71-392f22d74e51'}]",True
18,How can national authorities align market surveillance with Union financial laws while maintaining entity independence?,"['as appropriate, into their existing supervisory mechanisms and procedures under the relevant Union financial services law. It is appropriate to envisage that, when acting as market surveillance authorities under this Regulation, the national authorities responsible for the supervision of credit institutions regulated under Directive 2013/36/EU, which are participating in the Single Supervisory Mechanism established by Council Regulation (EU)\xa0No\xa01024/2013 ( 52 ) , should report, without delay, to the European Central Bank any information identified in the course of their market surveillance activities that may be of potential interest for the European Central Bank’s prudential supervisory tasks as specified in that Regulation. To further', 'take measures in relation to all AI systems when they present a\xa0risk in accordance with this Regulation. Due to the specific nature of Union institutions, agencies and bodies falling within the scope of this Regulation, it is appropriate to designate the European Data Protection Supervisor as a\xa0competent market surveillance authority for them. This should be without prejudice to the designation of national competent authorities by the Member States. Market surveillance activities should not affect the ability of the supervised entities to carry out their tasks independently, when such independence is required by Union law.']",National authorities can align market surveillance with Union financial laws by incorporating it into their existing supervisory mechanisms and procedures under the relevant Union financial services law. They should report any relevant information identified during market surveillance activities to the European Central Bank without delay. This alignment should not compromise the ability of supervised entities to carry out their tasks independently when required by Union law.,multi_context,"[{'source': 'eu_ai_act.html', 'id': '92d20938-ccc6-4efe-b72a-ba8f2ac153cc'}, {'source': 'eu_ai_act.html', 'id': '29377dcf-9049-4ea3-9b52-946b9994248c'}]",True
